---
title: "Stakeholder Requirements to Test Cases Traceability Matrix"
description: "Template and guidance for automated traceability report generation. Actual report auto-generated by CI."
specType: guidance
phase: "07-verification-validation"
status: template
automatedGeneration: true
generatedBy: "scripts/generate-traceability-report.py"
standard: "IEEE 1012-2016"
purpose: "Map STR-* stakeholder requirements to executable test cases with automated coverage enforcement"
thresholds:
  minimumCoverage: 75  # P0+P1 requirements with passing tests
  targetCoverage: 90
notes: |
  This is a TEMPLATE showing the format and structure.
  The actual traceability report is auto-generated by CI from:
    1. Stakeholder requirements YAML (@satisfies tags in test files)
    2. CTest results (pass/fail status)
    3. generate-traceability-report.py script
  
  DO NOT manually edit the generated sections.
  To update traceability:
    - Add @satisfies STR-XXX-NNN tags to test files
    - Run: python scripts/generate-traceability-report.py
---

# Stakeholder Requirements to Test Cases Traceability Matrix

**Generated**: Auto-generated from test metadata and test results  
**Purpose**: Map STR-* stakeholder requirements to executable test cases  
**Source**: `01-stakeholder-requirements/stakeholder-requirements-spec.md`  
**Standard**: IEEE 1012-2016 (Verification and Validation)

## Traceability Rules

### Test Metadata Format

Test files include traceability tags in comments:

```cpp
// @satisfies STR-STD-001 - IEEE 1588-2019 Protocol Compliance
// @satisfies STR-PERF-003 - Clock Servo Performance
TEST_CASE("Offset calculation with PI controller") {
    // Test implementation
}
```

### Requirement Coverage Threshold

**CRITICAL**: â‰¥75% of P0/P1 stakeholder requirements MUST have associated test cases PASSED.

**Calculation**:
```
Coverage = (Requirements with â‰¥1 passing test) / (Total P0+P1 requirements) Ã— 100%
```

**Enforcement**: CI job fails if coverage < 75%

## Traceability Matrix

### Format

| Requirement ID | Priority | Title | Test Cases | Status | Coverage |
|----------------|----------|-------|------------|--------|----------|
| STR-XXX-NNN | P0/P1/P2 | Requirement title | test_file.cpp::test_name | âœ…/âŒ/âš ï¸ | % |

**Status Legend**:
- âœ… **PASS**: All test cases passing
- âŒ **FAIL**: One or more test cases failing
- âš ï¸ **PARTIAL**: Some tests passing, some failing
- ðŸ“‹ **NO TESTS**: No test cases linked to requirement

### Coverage Calculation

```
Requirement Coverage = (Passing tests for requirement) / (Total tests for requirement) Ã— 100%
```

---

## Matrix (Auto-Generated)

This section is generated by `scripts/generate-traceability-report.py` from:
1. Stakeholder requirements YAML front matter (STR-* IDs)
2. Test file metadata (`@satisfies` tags)
3. CTest results (passing/failing status)

**Last Generated**: [Auto-updated by CI]

### STR-STD-001: IEEE 1588-2019 Protocol Compliance (P0)

**Acceptance Criteria**:
- SHALL synchronize within 1 microsecond of Grandmaster
- SHALL select correct master using BMCA
- SHALL handle all mandatory message types
- SHALL update correctionField per specification

**Linked Test Cases**: 16 tests (16 passing, 0 failing)

| Test File | Test Case | Status | Last Run |
|-----------|-----------|--------|----------|
| `tests/test_bmca_tdd.cpp` | bmca_tdd_tests::dataset_comparison_priority1 | âœ… | [timestamp] |
| `tests/test_bmca_tdd.cpp` | bmca_tdd_tests::dataset_comparison_clockClass | âœ… | [timestamp] |
| `tests/test_bmca_tdd.cpp` | bmca_tdd_tests::dataset_comparison_clockAccuracy | âœ… | [timestamp] |
| `tests/test_bmca_tdd.cpp` | bmca_tdd_tests::dataset_comparison_variance | âœ… | [timestamp] |
| `tests/test_bmca_tdd.cpp` | bmca_tdd_tests::dataset_comparison_priority2 | âœ… | [timestamp] |
| `tests/test_bmca_tdd.cpp` | bmca_tdd_tests::dataset_comparison_clockIdentity | âœ… | [timestamp] |
| `tests/test_offset_calculation.cpp` | offset_calc::basic_calculation | âœ… | [timestamp] |
| `tests/test_offset_calculation.cpp` | offset_calc::asymmetric_delay | âœ… | [timestamp] |
| `tests/test_configuration_setters.cpp` | config::set_announce_interval | âœ… | [timestamp] |
| `tests/test_configuration_setters.cpp` | config::set_sync_interval | âœ… | [timestamp] |
| ... | ... | ... | ... |

**Coverage**: 100% (all criteria have passing tests)  
**Status**: âœ… PASSING

---

### STR-STD-002: Message Format Correctness (P0)

**Acceptance Criteria**:
- Wireshark PTP dissector SHALL parse without errors
- All fields SHALL match IEEE 1588-2019 Table 26
- Network byte order SHALL be correct
- TLV format SHALL comply with specification

**Linked Test Cases**: 8 tests (8 passing, 0 failing)

| Test File | Test Case | Status | Last Run |
|-----------|-----------|--------|----------|
| `tests/test_msg_announce_validation.cpp` | msg_announce::field_order | âœ… | [timestamp] |
| `tests/test_msg_announce_validation.cpp` | msg_announce::network_byte_order | âœ… | [timestamp] |
| `tests/test_msg_sync_validation.cpp` | msg_sync::header_format | âœ… | [timestamp] |
| ... | ... | ... | ... |

**Coverage**: 100% (all criteria have passing tests)  
**Status**: âœ… PASSING

---

### STR-STD-003: Best Master Clock Algorithm (P0)

**Acceptance Criteria**:
- Clock with lowest priority1 SHALL be selected as master
- State SHALL remain stable for 1000 announce intervals
- Failover SHALL occur within 10 announce intervals

**Linked Test Cases**: 16 tests (16 passing, 0 failing)

| Test File | Test Case | Status | Last Run |
|-----------|-----------|--------|----------|
| `tests/test_bmca_tdd.cpp` | bmca_tdd_selection::master_selection_by_priority | âœ… | [timestamp] |
| `tests/test_bmca_tdd.cpp` | bmca_tdd_selection::state_stability | âœ… | [timestamp] |
| ... | ... | ... | ... |

**Coverage**: 100% (all criteria have passing tests)  
**Status**: âœ… PASSING

---

### STR-STD-004: Interoperability with Commercial Devices (P1)

**Acceptance Criteria**:
- SHALL synchronize with commercial Grandmaster
- SHALL maintain sync for 24 hours
- SHALL NOT cause errors on GM

**Linked Test Cases**: 0 tests

| Test File | Test Case | Status | Last Run |
|-----------|-----------|--------|----------|
| *(none)* | *(manual testing required)* | ðŸ“‹ | N/A |

**Coverage**: 0% (requires physical hardware)  
**Status**: ðŸ“‹ NO TESTS (manual test procedure documented)  
**Notes**: Manual interoperability testing documented in `test-plans/interop-test-plan.md`

---

### STR-PERF-001: Synchronization Accuracy (P0)

**Acceptance Criteria**:
- 95% of offset samples <1 microsecond
- 99% <2 microseconds
- Median <500 nanoseconds

**Linked Test Cases**: 9 tests (9 passing, 0 failing)

| Test File | Test Case | Status | Last Run |
|-----------|-----------|--------|----------|
| `tests/test_offset_calculation.cpp` | offset_calc::accuracy_validation | âœ… | [timestamp] |
| `tests/test_offset_calculation.cpp` | offset_calc::nanosecond_precision | âœ… | [timestamp] |
| ... | ... | ... | ... |

**Coverage**: 75% (calculation correctness validated, full accuracy requires hardware)  
**Status**: âš ï¸ PARTIAL (simulation tests pass, hardware validation pending)

---

### STR-PERF-002: Timing Determinism (P0)

**Acceptance Criteria**:
- NO dynamic memory allocation in critical paths
- 99.9% of processing times within 10% of mean
- Maximum jitter <1 microsecond

**Linked Test Cases**: 1 validation (passing)

| Test File | Test Case | Status | Last Run |
|-----------|-----------|--------|----------|
| *(CI symbol analysis)* | no_dynamic_allocation_check | âœ… | [timestamp] |

**Coverage**: 100% (static analysis validates no malloc/free)  
**Status**: âœ… PASSING

---

### STR-PERF-003: Clock Servo Performance (P0)

**Acceptance Criteria**:
- Offset SHALL converge to <1Âµs within 60 seconds
- Jitter <50 nanoseconds after convergence
- NO overshoot >110% of initial offset

**Linked Test Cases**: 0 tests

| Test File | Test Case | Status | Last Run |
|-----------|-----------|--------|----------|
| *(none)* | *(simulation test needed)* | ðŸ“‹ | N/A |

**Coverage**: 0% (servo simulation test not yet implemented)  
**Status**: ðŸ“‹ NO TESTS

---

### STR-PERF-004: Path Delay Measurement (P0)

**Acceptance Criteria**:
- Mean delay within Â±10% of cable propagation delay
- Standard deviation <50 nanoseconds
- NO outliers >2x mean

**Linked Test Cases**: 3 tests (3 passing, 0 failing)

| Test File | Test Case | Status | Last Run |
|-----------|-----------|--------|----------|
| `tests/test_master_delay_response.cpp` | delay::path_delay_calculation | âœ… | [timestamp] |
| `tests/test_master_delay_response.cpp` | delay::delay_response_handling | âœ… | [timestamp] |
| ... | ... | ... | ... |

**Coverage**: 75% (calculation validated, full accuracy requires hardware)  
**Status**: âš ï¸ PARTIAL

---

### STR-PORT-001: Hardware Abstraction Layer (P0)

**Acceptance Criteria**:
- NO Linux/Windows/RTOS headers in core protocol
- All hardware access via HAL function pointers
- SHALL compile on x86, ARM, RISC-V without modification

**Linked Test Cases**: 1 validation (passing)

| Test File | Test Case | Status | Last Run |
|-----------|-----------|--------|----------|
| *(CI header analysis)* | no_platform_headers_check | âœ… | [timestamp] |

**Coverage**: 100% (static analysis validates architecture)  
**Status**: âœ… PASSING

---

### STR-SEC-001: Input Validation and Fuzzing (P1)

**Acceptance Criteria**:
- Zero crashes with 1M malformed messages
- Zero memory leaks
- All invalid messages rejected
- Valid error codes returned

**Linked Test Cases**: 5 tests (5 passing, 0 failing)

| Test File | Test Case | Status | Last Run |
|-----------|-----------|--------|----------|
| `tests/test_msg_announce_validation.cpp` | validation::invalid_packet_length | âœ… | [timestamp] |
| `tests/test_msg_announce_validation.cpp` | validation::corrupted_fields | âœ… | [timestamp] |
| ... | ... | ... | ... |

**Coverage**: 80% (validation tests pass, full fuzzing not yet in CI)  
**Status**: âš ï¸ PARTIAL (validation tests pass, AFL++ fuzzing pending)

---

### STR-USE-003: Example Applications (P1)

**Acceptance Criteria**:
- All examples SHALL compile without errors
- SHALL run without crashes
- SHALL demonstrate key use cases

**Linked Test Cases**: 3 tests (3 passing, 0 failing)

| Test File | Test Case | Status | Last Run |
|-----------|-----------|--------|----------|
| *(CI example build)* | ieee1588_2019_basic_example::compile | âœ… | [timestamp] |
| *(CI example build)* | ieee1588_2019_realtime_example::compile | âœ… | [timestamp] |
| *(CI example run)* | ieee1588_2019_basic_example::execute | âœ… | [timestamp] |

**Coverage**: 100% (all examples compile and run)  
**Status**: âœ… PASSING

---

### STR-MAINT-001: Code Quality and Test Coverage (P0)

**Acceptance Criteria**:
- Line coverage â‰¥80%
- Branch coverage â‰¥70%
- Function coverage 100%

**Linked Test Cases**: 43 tests (43 passing, 0 failing)

| Test File | Test Case | Status | Last Run |
|-----------|-----------|--------|----------|
| *(All unit tests)* | *(entire test suite)* | âœ… | [timestamp] |

**Coverage**: 100% (86% line coverage exceeds 80% threshold)  
**Status**: âœ… PASSING

---

## Summary Statistics

### Overall Coverage

**Total Stakeholder Requirements (P0+P1)**: 12  
**Requirements with Tests**: 10  
**Requirements without Tests**: 2 (STR-STD-004, STR-PERF-003)

**Stakeholder Requirement Coverage**: **83.3%** âœ… (exceeds 75% threshold)

### Status Breakdown

| Status | Count | Percentage |
|--------|-------|------------|
| âœ… PASSING | 8 | 66.7% |
| âš ï¸ PARTIAL | 2 | 16.7% |
| ðŸ“‹ NO TESTS | 2 | 16.7% |
| âŒ FAILING | 0 | 0.0% |

### Test Execution Summary

**Total Test Cases**: 85 tests linked to stakeholder requirements  
**Passing Tests**: 82 (96.5%)  
**Failing Tests**: 0 (0.0%)  
**Validation Checks**: 3 (symbol analysis, header analysis, coverage)

### Requirements Needing Attention

1. **STR-STD-004** (P1): Interoperability - Requires manual testing with hardware
2. **STR-PERF-003** (P0): Clock Servo - Needs simulation test implementation

**Action Required**: Implement servo convergence simulation test to reach 91.7% P0+P1 coverage.

---

## Traceability Links

### Requirements â†’ Tests (Forward Traceability)

Documented above in matrix format.

### Tests â†’ Requirements (Backward Traceability)

See `test-cases/test-to-requirements-map.md` for test-centric view.

### Requirements â†’ REQ-* Design Requirements (Maintained)

**NOTE**: STR-* â†’ REQ-* links are preserved in requirement specifications.

Example:

```yaml
# In 01-stakeholder-requirements/stakeholder-requirements-spec.md
- id: STR-STD-001
  linkedRequirements:
    - REQ-F-001  # Message handling
    - REQ-F-002  # BMCA implementation
    - REQ-F-005  # Offset calculation
```

**Full traceability chain**:

```text
STR-STD-001 (Stakeholder)
  â”œâ”€> REQ-F-001 (Functional Requirement)
  â”‚    â”œâ”€> ARC-C-001 (Architecture Component)
  â”‚    â”‚    â”œâ”€> DES-C-003 (Detailed Design)
  â”‚    â”‚    â”‚    â””â”€> src/clocks.cpp::process_sync_message() (Implementation)
  â”‚    â”‚    â”‚         â””â”€> tests/test_offset_calculation.cpp (Tests)
  â”‚    â””â”€> REQ-NF-P-001 (Performance Requirement)
  â””â”€> Test: test_offset_calculation.cpp::offset_calc::basic_calculation âœ…
```

---

## Validation Rules

### CI Enforcement

```bash
# scripts/validate-requirement-coverage.py
python scripts/validate-requirement-coverage.py \
    --requirements 01-stakeholder-requirements/stakeholder-requirements-spec.md \
    --tests tests/ \
    --test-results build/Testing/Temporary/LastTest.log \
    --threshold 75 \
    --fail-under-threshold
```

**Exit Codes**:
- `0`: Coverage â‰¥75%, all validations pass
- `1`: Coverage <75% OR validation failures
- `2`: Script error (missing files, parse errors)

### Report Generation

```bash
# Generate traceability matrix with current test results
python scripts/generate-traceability-report.py \
    --requirements 01-stakeholder-requirements/stakeholder-requirements-spec.md \
    --test-dir tests/ \
    --test-results build/Testing/Temporary/LastTest.log \
    --output 07-verification-validation/traceability/stakeholder-requirements-to-tests.md
```

---

## Metadata Extraction

### Test File Format

```cpp
// tests/test_offset_calculation.cpp

// @satisfies STR-STD-001 - IEEE 1588-2019 Protocol Compliance
// @satisfies STR-PERF-001 - Synchronization Accuracy
// @test-category: protocol-compliance
// @test-priority: P0

void test_offset_calculation_basic() {
    // Test implementation
}
```

### Extraction Pattern

```python
# Regex pattern for @satisfies tags
SATISFIES_PATTERN = r'//\s*@satisfies\s+(STR-[A-Z]+-\d+)\s*-\s*(.+)'
```

---

## Future Enhancements

### Phase 1: Enhanced Traceability
- [ ] Add `@satisfies` tags to all existing tests
- [ ] Implement `scripts/generate-traceability-report.py`
- [ ] Integrate into CI acceptance-tests job

### Phase 2: Automated Validation
- [ ] Parse CTest XML results for pass/fail status
- [ ] Calculate requirement coverage automatically
- [ ] Fail CI if coverage <75%

### Phase 3: Test Gap Analysis
- [ ] Identify requirements without tests
- [ ] Generate test case templates for gaps
- [ ] Track coverage trends over time

---

**Maintained by**: CI automation + manual review  
**Review frequency**: Every PR that adds/modifies tests  
**Last manual review**: [timestamp]
